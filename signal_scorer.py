#!/usr/bin/env python3
"""
INSIDER CLUSTER SIGNAL SCORER
=================================
Scores insider buying clusters detected by the daily Form 4 scanner
against backtested signal filters.

Reads from the backtest results database to compute confidence
intervals, then scores new clusters from the daily scanner.

Can run standalone against the backtest DB (--backtest-review mode)
or score new clusters from the daily scanner DB (--score mode).

BACKTESTED SIGNAL TIERS (2020-2025, 5,774 signals):

  TIER 1 — "CONVICTION BUY" (Short-term, 5-10 day hold)
    Filter: C-Suite involved + Total value >= $5M
    5d Alpha: +4.08%  |  5d Win: 57.4%  |  n=230
    Edge: Massive executive conviction. Alpha fades after 20d.

  TIER 2 — "STRONG SIGNAL" (Short-term, 5-20 day hold)
    Filter: C-Suite involved + Total value >= $500K
    5d Alpha: +1.81%-2.43%  |  5d Win: 54-57%  |  n=423-742
    Edge: Broad C-Suite conviction with meaningful dollar commitment.

  TIER 3 — "MEAN REVERSION" (Long-term, 40-60 day hold)
    Filter: C-Suite involved + Total value >= $500K + Beaten down (>10% below cluster avg)
    60d Alpha: +13.44%  |  60d Win: 55.3%  |  n=320
    Edge: Beaten-down stocks where insiders are loading. Slow payoff.

  WATCH — "INFORMATIONAL" (No proven edge)
    Clusters that don't meet tier criteria. Still worth monitoring.

  AVOID — "ANTI-PATTERN"
    No C-Suite + small dollar value, or elevated stocks with small buys.
    These historically show negative alpha.

HONEST CAVEATS:
  - Tier 1 has only 230 historical signals (~46/year). Confidence
    intervals are wide. Treat as promising but not proven.
  - Tier 3 has strong alpha but sub-50% short-term win rates.
    You WILL have drawdowns before the payoff.
  - All alphas are before transaction costs.
  - Past performance ≠ future results. This is a starting framework.

Usage:
    python3 signal_scorer.py --backtest-review    # Analyze historical tiers
    python3 signal_scorer.py --score              # Score today's clusters
    python3 signal_scorer.py --score --email      # Score and email report

Requires:
    - insider_backtest_results.db (from insider_cluster_backtest.py)
    - For --score mode: daily scanner database (form4_scanner.db or similar)
"""

import sqlite3
import os
import sys
import math
import argparse
from datetime import datetime, timedelta

# ============================================================
#  CONFIGURATION
# ============================================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Backtest database (generated by insider_cluster_backtest.py)
BACKTEST_DB = os.path.join(BASE_DIR, "insider_backtest_results.db")

# Output
REPORT_DIR = BASE_DIR


# ============================================================
#  TIER DEFINITIONS
# ============================================================

TIERS = [
    {
        'name': 'TIER 1 — CONVICTION BUY',
        'tag': 'T1',
        'hold': '5-10 days',
        'description': 'C-Suite + $5M+ total value',
        'filter_sql': 'has_csuite = 1 AND total_dollars >= 5000000',
        'filter_fn': lambda r: r['has_csuite'] and r['total_dollars'] >= 5_000_000,
        'key_window': '5d',
    },
    {
        'name': 'TIER 2 — STRONG SIGNAL',
        'tag': 'T2',
        'hold': '5-20 days',
        'description': 'C-Suite + $500K+ total value',
        'filter_sql': 'has_csuite = 1 AND total_dollars >= 500000',
        'filter_fn': lambda r: r['has_csuite'] and r['total_dollars'] >= 500_000,
        'key_window': '5d',
    },
    {
        'name': 'TIER 3 — MEAN REVERSION',
        'tag': 'T3',
        'hold': '40-60 days',
        'description': 'C-Suite + $500K+ + Beaten down (>10% below cluster avg)',
        'filter_sql': (
            'has_csuite = 1 AND total_dollars >= 500000 '
            'AND avg_price > 0 AND ((entry_price * 1.0 / avg_price) - 1) * 100 < -10'
        ),
        'filter_fn': lambda r: (
            r['has_csuite'] and r['total_dollars'] >= 500_000
            and r['avg_price'] > 0
            and ((r['entry_price'] / r['avg_price']) - 1) * 100 < -10
        ),
        'key_window': '60d',
    },
]

ANTI_PATTERNS = [
    {
        'name': 'NO C-SUITE + SMALL VALUE',
        'description': 'No C-Suite officers + Under $100K total',
        'filter_sql': 'has_csuite = 0 AND total_dollars < 100000',
        'filter_fn': lambda r: not r['has_csuite'] and r['total_dollars'] < 100_000,
    },
    {
        'name': 'NO C-SUITE + ELEVATED',
        'description': 'No C-Suite + stock >10% above cluster avg',
        'filter_sql': (
            'has_csuite = 0 AND avg_price > 0 '
            'AND ((entry_price * 1.0 / avg_price) - 1) * 100 > 10'
        ),
        'filter_fn': lambda r: (
            not r['has_csuite']
            and r.get('avg_price', 0) > 0
            and ((r['entry_price'] / r['avg_price']) - 1) * 100 > 10
        ),
    },
]


# ============================================================
#  STATISTICAL HELPERS
# ============================================================

def confidence_interval(values, confidence=0.95):
    """Calculate mean and confidence interval for a list of values."""
    n = len(values)
    if n < 2:
        return None, None, None
    
    mean = sum(values) / n
    variance = sum((x - mean) ** 2 for x in values) / (n - 1)
    std_err = math.sqrt(variance / n)
    
    # Use t-distribution approximation for small samples
    # For 95% CI: z ≈ 1.96 for large n, ~2.0 for n>30
    if n > 120:
        z = 1.96
    elif n > 60:
        z = 2.0
    elif n > 30:
        z = 2.04
    else:
        z = 2.1  # conservative for small n
    
    ci_low = mean - z * std_err
    ci_high = mean + z * std_err
    
    return mean, ci_low, ci_high


def win_rate_ci(wins, total, confidence=0.95):
    """Wilson score interval for win rate."""
    if total == 0:
        return 0, 0, 0
    
    p = wins / total
    z = 1.96
    
    denominator = 1 + z**2 / total
    centre = p + z**2 / (2 * total)
    spread = z * math.sqrt((p * (1 - p) + z**2 / (4 * total)) / total)
    
    ci_low = (centre - spread) / denominator
    ci_high = (centre + spread) / denominator
    
    return p, ci_low, ci_high


# ============================================================
#  BACKTEST REVIEW MODE
# ============================================================

def backtest_review():
    """Analyze historical performance of each tier with confidence intervals."""
    
    if not os.path.exists(BACKTEST_DB):
        print(f"ERROR: Backtest database not found at {BACKTEST_DB}")
        sys.exit(1)
    
    conn = sqlite3.connect(BACKTEST_DB)
    conn.row_factory = sqlite3.Row
    
    total = conn.execute("SELECT COUNT(*) FROM backtest_results").fetchone()[0]
    print(f"\n{'='*72}")
    print(f"  SIGNAL TIER REVIEW — Statistical Confidence Analysis")
    print(f"  Database: {total:,} historical signals")
    print(f"{'='*72}")
    
    windows = [5, 10, 20, 40, 60]
    
    for tier in TIERS:
        print(f"\n{'─'*72}")
        print(f"  {tier['name']}")
        print(f"  Filter: {tier['description']}")
        print(f"  Suggested hold: {tier['hold']}")
        print(f"{'─'*72}")
        
        where = tier['filter_sql']
        
        n = conn.execute(
            f"SELECT COUNT(*) FROM backtest_results WHERE {where} AND ret_5d IS NOT NULL"
        ).fetchone()[0]
        
        if n < 10:
            print(f"  Too few signals ({n})")
            continue
        
        freq_per_year = n / 5.0  # ~5 years of data
        print(f"  Signals: {n:,}  (~{freq_per_year:.0f}/year, ~{freq_per_year/52:.1f}/week)")
        print()
        
        print(f"    Window | Avg Alpha |   95% CI Range  | Alpha Win | CI Range     | Sharpe-like")
        print(f"  -------- | --------- | --------------- | --------- | ------------ | -----------")
        
        for w in windows:
            ac = f"alpha_{w}d"
            
            rows = conn.execute(
                f"SELECT {ac} FROM backtest_results WHERE {where} AND {ac} IS NOT NULL"
            ).fetchall()
            
            if not rows:
                continue
            
            alphas = [r[0] for r in rows]
            cnt = len(alphas)
            wins = sum(1 for a in alphas if a > 0)
            
            mean, ci_lo, ci_hi = confidence_interval(alphas)
            wr, wr_lo, wr_hi = win_rate_ci(wins, cnt)
            
            # Sharpe-like ratio: mean alpha / std dev of alpha
            std = math.sqrt(sum((a - mean)**2 for a in alphas) / (cnt - 1))
            sharpe = mean / std if std > 0 else 0
            
            # Flag if CI includes zero (not statistically significant)
            sig = "✅" if ci_lo > 0 else "⚠️ " if mean > 0 else "❌"
            
            key = " ← KEY" if f"{w}d" == tier['key_window'] else ""
            
            print(f"    {w:4d}d | {mean:+7.2f}%  | [{ci_lo:+6.2f}%, {ci_hi:+6.2f}%] | "
                  f"   {wr*100:5.1f}% | [{wr_lo*100:4.1f}%, {wr_hi*100:4.1f}%] | "
                  f" {sharpe:+.3f} {sig}{key}")
        
        # Year-by-year breakdown
        print(f"\n    Year-by-year consistency:")
        years = conn.execute(
            f"SELECT DISTINCT year FROM backtest_results WHERE {where} AND ret_5d IS NOT NULL ORDER BY year"
        ).fetchall()
        
        key_w = int(tier['key_window'].replace('d', ''))
        ac = f"alpha_{key_w}d"
        
        for yr_row in years:
            yr = yr_row[0]
            yr_data = conn.execute(
                f"SELECT AVG({ac}), COUNT(*), "
                f"SUM(CASE WHEN {ac} > 0 THEN 1 ELSE 0 END) "
                f"FROM backtest_results WHERE {where} AND {ac} IS NOT NULL AND year = ?",
                [yr]
            ).fetchone()
            
            if yr_data[1] > 0:
                avg_a = yr_data[0]
                cnt_y = yr_data[1]
                wr_y = yr_data[2] / cnt_y * 100
                bar = "+" * max(0, int(avg_a / 0.5)) if avg_a > 0 else "-" * max(0, int(-avg_a / 0.5))
                print(f"      {yr}: {avg_a:+6.2f}% alpha ({wr_y:4.1f}% win, n={cnt_y:3d}) {bar}")
    
    # Anti-patterns
    print(f"\n{'─'*72}")
    print(f"  ANTI-PATTERNS (avoid these)")
    print(f"{'─'*72}")
    
    for ap in ANTI_PATTERNS:
        n = conn.execute(
            f"SELECT COUNT(*) FROM backtest_results WHERE {ap['filter_sql']} AND ret_5d IS NOT NULL"
        ).fetchone()[0]
        
        if n < 10:
            continue
        
        for w in [5, 20, 60]:
            ac = f"alpha_{w}d"
            row = conn.execute(
                f"SELECT AVG({ac}), SUM(CASE WHEN {ac} > 0 THEN 1 ELSE 0 END), COUNT(*) "
                f"FROM backtest_results WHERE {ap['filter_sql']} AND {ac} IS NOT NULL"
            ).fetchone()
            
            if w == 5:
                print(f"\n  ⛔ {ap['name']} (n={n}): {ap['description']}")
            
            if row[2] > 0:
                print(f"      {w}d alpha: {row[0]:+.2f}%  win: {row[1]/row[2]*100:.1f}%")
    
    # Sample size reality check
    print(f"\n{'='*72}")
    print(f"  SAMPLE SIZE REALITY CHECK")
    print(f"{'='*72}")
    print()
    t1_sql = TIERS[0]['filter_sql']
    t2_sql = TIERS[1]['filter_sql']
    t3_sql = TIERS[2]['filter_sql']
    t1_n = conn.execute(f"SELECT COUNT(*) FROM backtest_results WHERE {t1_sql} AND ret_5d IS NOT NULL").fetchone()[0]
    t2_n = conn.execute(f"SELECT COUNT(*) FROM backtest_results WHERE {t2_sql} AND ret_5d IS NOT NULL").fetchone()[0]
    t3_n = conn.execute(f"SELECT COUNT(*) FROM backtest_results WHERE {t3_sql} AND ret_5d IS NOT NULL").fetchone()[0]
    print(f"  Tier 1 (Conviction Buy):  {t1_n} signals over ~5 years")
    print(f"  Tier 2 (Strong Signal):   {t2_n} signals over ~5 years")
    print(f"  Tier 3 (Mean Reversion):  {t3_n} signals over ~5 years")
    print()
    print(f"  Rule of thumb: >200 signals is decent, >500 is solid, >1000 is robust.")
    print(f"  Tier 1 is at the lower bound. Use appropriate position sizing.")
    print()
    print(f"  Std deviations on 5d returns are 13-19%, meaning:")
    print(f"    - Even a +4% average alpha will produce frequent 10-15% losers")
    print(f"    - Position sizing matters more than signal selection")
    print(f"    - Never risk more than you can afford to lose on any single signal")
    
    conn.close()


# ============================================================
#  SCORE NEW CLUSTERS
# ============================================================

def score_cluster(cluster):
    """
    Score a single cluster dict against tier definitions.
    
    cluster dict should have:
        ticker, signal_date, num_insiders, total_dollars,
        avg_price, entry_price, has_csuite, has_ceo, has_cfo, roles
    
    Returns: (tier_tag, tier_name, notes)
    """
    
    # Check anti-patterns first
    for ap in ANTI_PATTERNS:
        try:
            if ap['filter_fn'](cluster):
                return ('AVOID', f"⛔ {ap['name']}", ap['description'])
        except (KeyError, TypeError, ZeroDivisionError):
            pass
    
    # Check tiers in order (most selective first)
    matched_tier = None
    for tier in TIERS:
        try:
            if tier['filter_fn'](cluster):
                matched_tier = tier
                break  # Take first (highest) matching tier
        except (KeyError, TypeError, ZeroDivisionError):
            pass
    
    if matched_tier:
        notes = []
        if cluster.get('has_ceo'):
            notes.append("CEO involved")
        if cluster.get('has_cfo'):
            notes.append("CFO involved")
        if cluster.get('total_dollars', 0) >= 10_000_000:
            notes.append(f"${cluster['total_dollars']/1e6:.1f}M total")
        elif cluster.get('total_dollars', 0) >= 1_000_000:
            notes.append(f"${cluster['total_dollars']/1e6:.1f}M total")
        else:
            notes.append(f"${cluster['total_dollars']/1e3:.0f}K total")
        
        # Price context
        if cluster.get('avg_price', 0) > 0 and cluster.get('entry_price', 0) > 0:
            pct = ((cluster['entry_price'] / cluster['avg_price']) - 1) * 100
            if pct < -10:
                notes.append(f"beaten down {pct:.0f}%")
            elif pct > 10:
                notes.append(f"elevated +{pct:.0f}%")
        
        return (matched_tier['tag'], matched_tier['name'], '; '.join(notes))
    
    # No tier matched — informational
    notes = []
    if not cluster.get('has_csuite'):
        notes.append("no C-Suite")
    if cluster.get('total_dollars', 0) < 500_000:
        notes.append(f"${cluster.get('total_dollars', 0)/1e3:.0f}K (below $500K threshold)")
    
    return ('WATCH', 'WATCH — Informational', '; '.join(notes) or 'Below tier thresholds')


def score_from_backtest_db():
    """Score all signals in the backtest database (for review/validation)."""
    
    if not os.path.exists(BACKTEST_DB):
        print(f"ERROR: Backtest database not found at {BACKTEST_DB}")
        sys.exit(1)
    
    conn = sqlite3.connect(BACKTEST_DB)
    conn.row_factory = sqlite3.Row
    
    # Get most recent signals
    rows = conn.execute("""
        SELECT ticker, signal_date, num_insiders, total_dollars,
               avg_price, entry_price, has_csuite, has_ceo, has_cfo, roles,
               ret_5d, alpha_5d, ret_20d, alpha_20d, ret_60d, alpha_60d
        FROM backtest_results
        WHERE ret_5d IS NOT NULL
        ORDER BY signal_date DESC
        LIMIT 100
    """).fetchall()
    
    print(f"\n{'='*72}")
    print(f"  SCORING RECENT HISTORICAL SIGNALS (most recent 100)")
    print(f"{'='*72}\n")
    
    # Count by tier
    tier_counts = {}
    tier_results = {}
    
    for row in rows:
        cluster = dict(row)
        tag, name, notes = score_cluster(cluster)
        
        tier_counts[tag] = tier_counts.get(tag, 0) + 1
        if tag not in tier_results:
            tier_results[tag] = []
        tier_results[tag].append(row)
    
    # Print summary
    print(f"  Distribution of last 100 signals:")
    for tag in ['T1', 'T2', 'T3', 'WATCH', 'AVOID']:
        if tag in tier_counts:
            print(f"    {tag:>6s}: {tier_counts[tag]:3d}")
    
    # Print T1 and T2 signals with outcomes
    for show_tag in ['T1', 'T2', 'T3']:
        if show_tag not in tier_results:
            continue
        
        tier_info = [t for t in TIERS if t['tag'] == show_tag][0]
        signals = tier_results[show_tag][:15]
        
        print(f"\n  {tier_info['name']} — Recent signals with outcomes:")
        print(f"    {'Ticker':<7s} {'Date':<11s} {'#':>2s} {'$Value':>11s} "
              f"{'5d α':>7s} {'20d α':>7s} {'60d α':>7s}  Roles")
        print(f"    {'-'*7} {'-'*11} {'-'*2} {'-'*11} "
              f"{'-'*7} {'-'*7} {'-'*7}  {'-'*20}")
        
        for s in signals:
            dv = f"${s['total_dollars']:,.0f}" if s['total_dollars'] else "?"
            def fmt(v): return f"{v:+6.1f}%" if v is not None else "   N/A"
            roles = (s['roles'] or "")[:20]
            print(f"    {s['ticker']:<7s} {str(s['signal_date'])[:10]:<11s} "
                  f"{s['num_insiders']:>2d} {dv:>11s} "
                  f"{fmt(s['alpha_5d'])} {fmt(s['alpha_20d'])} {fmt(s['alpha_60d'])}  {roles}")
    
    conn.close()


# ============================================================
#  GENERATE TEXT REPORT
# ============================================================

def generate_report(scored_signals, output_path=None):
    """Generate a text report of scored signals."""
    
    lines = []
    lines.append("=" * 72)
    lines.append("  INSIDER CLUSTER SIGNAL REPORT")
    lines.append(f"  Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append("=" * 72)
    lines.append("")
    
    # Group by tier
    by_tier = {}
    for sig in scored_signals:
        tag = sig['tier_tag']
        if tag not in by_tier:
            by_tier[tag] = []
        by_tier[tag].append(sig)
    
    for tag in ['T1', 'T2', 'T3', 'WATCH', 'AVOID']:
        if tag not in by_tier:
            continue
        
        sigs = by_tier[tag]
        tier_name = sigs[0]['tier_name']
        
        lines.append(f"  {tier_name} ({len(sigs)} signals)")
        lines.append("  " + "-" * 60)
        
        for sig in sigs:
            lines.append(f"    {sig['ticker']:<7s} | {sig['num_insiders']} insiders | "
                        f"${sig['total_dollars']:,.0f} | {sig['notes']}")
            if sig.get('roles'):
                lines.append(f"            Roles: {sig['roles']}")
        
        lines.append("")
    
    # Caveats
    lines.append("  " + "=" * 60)
    lines.append("  CAVEATS:")
    lines.append("    • Tier 1 based on ~46 signals/year — promising but low sample")
    lines.append("    • Tier 3 has 40-60 day payoff horizon — expect short-term pain")
    lines.append("    • All returns before transaction costs")
    lines.append("    • This is research output, not financial advice")
    lines.append("  " + "=" * 60)
    
    report = '\n'.join(lines)
    
    if output_path:
        with open(output_path, 'w') as f:
            f.write(report)
        print(f"  Report saved: {output_path}")
    
    return report


# ============================================================
#  MAIN
# ============================================================

def main():
    parser = argparse.ArgumentParser(description='Insider Cluster Signal Scorer')
    parser.add_argument('--backtest-review', action='store_true',
                       help='Review historical tier performance with confidence intervals')
    parser.add_argument('--score', action='store_true',
                       help='Score recent signals from backtest database')
    parser.add_argument('--email', action='store_true',
                       help='Email the report (requires email config)')
    
    args = parser.parse_args()
    
    if args.backtest_review:
        backtest_review()
    elif args.score:
        score_from_backtest_db()
    else:
        # Default: run both
        backtest_review()
        print("\n\n")
        score_from_backtest_db()


if __name__ == '__main__':
    main()